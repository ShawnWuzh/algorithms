# Map-Reduce和Hadoop逐渐成为面试热门。

# 哈希函数：
哈希函数又叫散列函数，哈希函数的输入域可以是非常大的范围，但是输出域是固定范围。假设为s
哈希函数的性质：
1. 典型的哈希函数都拥有无限的输入值域
2. 输入值相同时，返回值一样
3. 输入值不同时，返回值可能一样，也可能不一样
4. 不同输入值得到的哈希值，整体均匀的分布在输出域S上(重要)

1-3点性质是哈希函数的基础，第4点是评价哈希函数优劣的关键。
不同输入值得到的哈希值越均匀分布在S上，该哈希函数越优秀
输入范围（极大） 经过哈希函数计算后， 得到输出域S， 将输出域S对m求余，得到的数会均匀分布在0-m-1上，
MD5和SHA1算法都是经典的哈希函数算法，了解即可。

# Map-Reduce
1. Map阶段： 把大任务分成子任务
2. Reduce阶段： 子任务并发处理，然后合并结果
难点：工程上的处理

# 介绍Map-Reduce
注意点：
1. 备份的考虑，分布式存储的设计细节，以及容灾策略。
2. 任务分配策略与任务进度跟踪的细节设计，节点状态的呈现
3. 多用户权限的控制

# 例子
用map-reduce的方法统计一篇文章中每个单词出现的次数
首先经过预处理得到只包含单词之后的文本， 然后经过map阶段对每个单词生成词频为
1的记录（一个单词可能有多个词频为1的记录，此时还未进行合并），得到单个单词的
单一词频记录，通过哈希函数得到每个单词的哈希值，并根据该值分成若干组任务，然后
子任务中包含若干种单词，但是同一种单词不会分配进不同的子任务中。单个子任务中同一种单词的词频进行合并
最后得到同种单词合并后的组，最后把这些组统一合并就得到了我们最终的结果。

#  常见海量处理题目解题关键
1.分而治之，通过哈希函数将大任务分流到机器，或分流成小文件
2. 常用的hashMap或者bitmap
难点： 通讯，时间，空间的估算。

# 案例一
请对10亿个IPV4的IP地址进行排序，每一个IP只会出现一次。
我们可以通过将IP地址透过哈希函数得到一个哈希值，然后构建一个bitmap，
遍历这10亿个数，如果某个数出现，则bitmap上对应的值设为1，最后对于
bitmap上的每一个值，如果该值为1，则将该值对应的key hash成IP地址
即可。

# 案例二
请对10亿个人的年龄进行排序。
由于年龄的范围我们是知道的，所以本题排序显然可以直接使用基排序就可以了。

# 案例三
有一个包含20多亿个全是32位整数的大文件，在其中找到出现次数最多的数。但是内存限制只有2G
如果我们用一个hashmap记录所有数出现的次数，
4字节的整数 作为Key：具体某一种数
4字节的整数： 作为value，这种数出现的次数。
一条记录（key,value）占有8字节， 记录条数为2亿时，大约1.6G内存
所以用哈希表来直接统计20亿个整数的方案，会导致内存不足。
解决办法， 利用哈希函数进行分流，得到15个文件，然后分别对这15个文件进行用哈希表进行处理，全部处理完成之后，得到15个文件
中各自的第一名，15个第一名中，再选出其中的第一名。
注意：
同一种数不会被分流到不同文件，这是哈希函数性质决定的。
对于不同的数，每个文件中含有整数的种数几乎一样，这也是哈希函数性质决定的。所以每一个子文件中的整数数量不会超过20亿/15，因为
哈希函数是均匀分配的。

# 案例四
32位无符号整数的范围是0 - 4294967295. 现在有一个正好包含40亿个无符号整数的文件，所以在整个范围中必然有没出现过的数。
可以使用最多10M的内存，只用找到一个没有出现过的数即可，该如何找？

1. 根据内存限制决定区间大小， 根据区间大小，得到有多少个变量，来记录每个区间的数出现的次数。
2. 统计区间上的数的出现次数，找到不足的区间
3. 利用bitmap对不满的区间，进行这个区间上的数的词频统计。

# 案例五
某搜索公司一天的用户搜索词汇是海量的，假设有百亿的数据量，请设计一种求出每天最热100词的可行办法。

先使用哈希函数对数据进行分流， 分流道不同的机器上，然后，在每一个机器上，在利用哈希函数分流成一个个的
小文件。
处理每一个小文件，得到每一个小文件中词汇的词频统计，用哈希表建立记录后，利用小根堆来进行top100的筛选，然后
在每一台机器上，利用小根堆或外排序合并，得到每一台机器上的top100。
最后利用小根堆或外排序获得总体的一个top100.
*外部排序：大文件的排序，当待排序的文件很大时，无法将整个文件的所有记录同时调入内存进行排序，只能将文件存放在外存，
这种排序称作外部排序。一把提到的快排，堆排序，归并排序都是内排序，所谓内排序就是可以在内存中完成的排序。外部排序常用
的算法是多路归并排序，即将原文件分解成多个能够一次性装入内存的部分*

# 案例六
工程师常使用服务器集群来设计和实现数据缓存，以下是常见的策略：1. 无论是添加，查询，还是删除数据，都先将数据的id
通过哈希函数转换成一个哈希值，记为key。2. 如果目前机器有N台，则计算key % 的值，这个值就是该数据所属的机器编号，
无论是添加，删除还是查询操作，都只在这台机器上进行。请分析这种缓存策略可能带来的问题，并提出改进的方案。

潜在问题： 如果增加或删除机器，数据迁移的代价很大。 因为当机器数量改变的时候，因为我们需要用key对机器数量求余数，
从而导致数据归属的机器发生变化，导致所有数据都需要进行迁移。
解决办法： 一致性哈希算法
数据id通过哈希值计算后的结果为 0 - 2^32
然后将这些数连成一个环，将机器的的ID也通过哈希值计算，放入这个环中，对于每一个数据id，根据他在哈希值中的环，选择
顺时针方向离他最近的机器，这样当我们要删除一个机器的时候，就只需将该机器到上一个机器之间的数据迁移到该机器的下一个
机器中，而其他的数据不需要作出改变。
